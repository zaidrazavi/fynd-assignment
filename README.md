# Fynd AI Engineering Intern â€“ Assignment

This repository contains my submission for the **AI Engineering Intern â€“ Fynd** assignment.

It includes:

- A **User Feedback App** (Streamlit) â€“ customers submit ratings & reviews and get an AI-generated reply
- An **Admin Dashboard** (Streamlit) â€“ internal view of all feedback + analytics
- A **prompting notebook** for **Task 1 â€“ Rating Prediction via Prompting**
- A short **report (PDF)** summarizing the approach and results

---

## ğŸ“ Project Structure

```text
fynd-assignment/
â”œâ”€â”€ admin_app.py                     # Admin analytics dashboard (Streamlit)
â”œâ”€â”€ user_app.py                      # User feedback portal (Streamlit)
â”œâ”€â”€ fynd_task1_rating_prompting.ipynb# Task 1 notebook (Yelp rating via prompts)
â”œâ”€â”€ yelp.csv                         # Sampled/cleaned Yelp dataset used in Task 1
â”œâ”€â”€ feedback.csv                     # Stored feedback from user app
â”œâ”€â”€ feedback_log.csv                 # Optional log of submissions
â”œâ”€â”€ report.pdf                       # Assignment report (Task 1 + apps)
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md                        # This file
ğŸŒ Live Apps
User Feedback App
ğŸ‘‰ https://fynd-assignment-fwgwkcfa9fbhhckzx35wrs.streamlit.app/

Admin Dashboard
ğŸ‘‰ https://fynd-assignment-yrbtvmcjurvfkvssd6wfpi.streamlit.app/

ğŸ§ª Task 1 â€“ Rating Prediction via Prompting
Notebook: fynd_task1_rating_prompting.ipynb

Goal:
Given a Yelp review, predict a rating from 1â€“5 stars using prompting only, returning:

json
Copy code
{
  "predicted_stars": 4,
  "explanation": "Brief reasoning for the assigned rating."
}
Dataset
Kaggle Yelp Reviews dataset (subset)

Columns used: text (review), stars (actual rating 1â€“5)

Cleaning & Sampling
Removed rows with missing stars or text

Kept ratings between 1 and 5

Lowercased text, removed URLs, punctuation and extra spaces

Sampled a subset of reviews for evaluation

Prompt Variants
Three prompt styles were tested:

Prompt 1 â€“ Strict rater

Short rubric, clear mapping 1â€“5

Force JSON output

Prompt 2 â€“ Step-by-step reasoning

First classify sentiment and intensity

Then map to rating 1â€“5

Still forced JSON output

Prompt 3 â€“ Aspect-based

Ask model to separately consider food, service, ambiance, price

Then decide final rating from 1â€“5

Force JSON output

Each prompt instructs the model to return only JSON with predicted_stars and explanation.

Evaluation
For each prompt we measured:

Accuracy â€“ (predicted_stars == actual)

JSON validity rate â€“ share of responses parsed successfully as valid JSON

Example summary (for the sampled set used in my run):

Prompt	Accuracy	JSON Validity
Prompt 1	0.38	0.11
Prompt 2	0.36	0.10
Prompt 3	0.38	0.09

Short Discussion
All three prompts achieved similar accuracy, around 35â€“38% on the sampled reviews.

Prompt 1 (simplest) was already competitive, showing that a clear rubric works well.

Prompt 2 and Prompt 3 sometimes produced overly long explanations or slightly off-format JSON, which reduced JSON validity rate.

The main failure modes:

Confusing mixed reviews (good food / bad service)

Being too generous with 4â€“5 star ratings

Rarely outputting invalid JSON (extra text around the JSON or different key name)

ğŸ’» Apps Overview
1. User Feedback App â€“ user_app.py
Features:

User selects a rating (1â€“5) and writes a short review

App calls Gemini API to generate:

A friendly response to the user

It also stores:

rating

review

AI reply

Recent feedback is shown in a table for the userâ€™s session

2. Admin Dashboard â€“ admin_app.py
Features:

Loads feedback.csv generated by the user app

Shows a raw feedback table:

user rating

review text

AI reply

AI summary (optional)

AI-recommended actions (optional)

Summary analytics:

total number of feedback entries

average rating

count of low ratings (â‰¤ 2)

Rating distribution chart

Latest feedback section

The admin dashboard and user app both read from / write to the same data source (feedback.csv).

âš™ï¸ Local Setup
Clone the repo

bash
Copy code
git clone https://github.com/zaidrazavi/fynd-assignment.git
cd fynd-assignment
Install dependencies

bash
Copy code
pip install -r requirements.txt
Set the Gemini API key

On Windows (PowerShell):

bash
Copy code
setx GEMINI_API_KEY "your_api_key_here"
On Linux / macOS:

bash
Copy code
export GEMINI_API_KEY="your_api_key_here"
Run the apps

User app:

bash
Copy code
streamlit run user_app.py
Admin app:

bash
Copy code
streamlit run admin_app.py
ğŸ§° Tech Stack
Python

Streamlit

Gemini API (google-genai)

Pandas, NumPy

Plotly (for charts)

ğŸ‘¤ Author
Mohd Zayed Kazim Shalil (Zaid Razavi)
AI Engineering Intern Applicant â€“ Fynd

markdown
Copy code
